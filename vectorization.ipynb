{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a genomic region (union of continous DNA portions) segmented into short DNA words, we build a statistics taking into account the frequency of occurrence of each word and the frequency of co-occurrence of pairs of words in the same window (this can be the fragment or a larger bin in the genome). We can keep the information about the linear location of the fragments or not (the best strategy can be chosen afterwards depending on the result of clustering, for example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim, logging\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "###############################################################                                                                                                                                             \n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a bam file, we select the 50bp left/right extension of the reference locations (reference genome is GRCh37). We tokenize these fragments and build a document-term matrix from the segmented chr 1 to 22 (no X, Y and MT). This matrix is extremely sparse given tha large size of the vocabulary and the small number of terms per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1) # set the min numb of times a word can occur\n",
    "corpus = open('/home/garner1/Work/dataset/refgenomeLP/docs/1.doc')\n",
    "dtm = vectorizer.fit_transform(corpus) # get document-term matrix                                                                                                                                           \n",
    "vocab = vectorizer.get_feature_names() # a list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the occurrence of each unique word in the list of documents, and observe how the majority of the words is rare and there are few words shared by the majority of the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dtm.shape)\n",
    "dtm_word = dtm.sum(axis=0)\n",
    "print (dtm_word.shape)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "ax = sns.distplot(dtm_word[(dtm_word<10000) & (dtm_word>1)], bins=20, kde=False)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('number of unique words occurring x times')\n",
    "ax.set_xlabel('x = number of documents sharing a given unique word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the document-term matrix using truncated SVD (note that singular values are sorted in ascending order). This identifies main \"topics\" (each one an ensemble of words of different weights, as expressed by vt rows), and the relevance of each topic for the list of documents is given by u columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds, eigs\n",
    "\n",
    "u, s, vt = svds(dtm.asfptype(), k=10)\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.pointplot(range(len(s)),s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "# prepare some data\n",
    "mode = 8\n",
    "#x = range(len(u[:,vec]))\n",
    "#y = u[:,vec]\n",
    "x = range(len(vt[mode,:]))\n",
    "y = vt[mode,:]\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"lines.html\")\n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"eigenword\", x_axis_label='document', y_axis_label='y')\n",
    "\n",
    "# add a line renderer with legend and line thickness\n",
    "p.circle(x, y, legend=\"Temp.\", size=6)\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A term-term co-occurence matrix is obtained as the product of dtm.T * dtm. This also is a sparse matrix and, after truncated SVD, we can identify main eigenwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from numpy import *\n",
    "\"\"\"\n",
    "Compute the PPMI values for the raw co-occurrence matrix.\n",
    "PPMI values will be written to mat and it will get overwritten.\n",
    "\"\"\"    \n",
    "mat = dtm.transpose().dot(dtm)      # build word-word matrix\n",
    "rows,cols = mat.nonzero() # get the list of non-zero rows and cols index\n",
    "data = np.divide(mat.data*1.0,dtm_word[0,rows]*1.0) # pointwise division of data matrix by row-sum\n",
    "data = np.divide(data,dtm_word[0,cols]*1.0) # pointwise division by col-sum\n",
    "data = data*dtm_word.sum() #rescaling by number of tokens\n",
    "data = np.squeeze(np.asarray(data))\n",
    "\n",
    "coomat = coo_matrix((data, (rows, cols)), shape=mat.shape) # sparse mat in coordinate format\n",
    "coomat.data = ma.log(coomat.data)\n",
    "coomat.data = ma.masked_less(coomat.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "[u,s,vt] = svds(coomat, k=6, which='LM', return_singular_vectors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
